{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1524, 170)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all_features.csv', index_col= None)\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.decomposition import PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.dropna(axis=0, how='any')\n",
    "X = data\n",
    "X = X.drop(['filenum','filename','classified_shape'] , axis = 1)\n",
    "X_norm = normalize(X)\n",
    "Y = data['classified_shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  \n",
    "scaler.fit(X)  \n",
    "\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X,Y,\n",
    "    test_size=0.25,\n",
    "    random_state=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 18\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized',\n",
    "          whiten=True).fit(X)\n",
    "\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Remove PCA \n",
    "X_train_pca = X_train\n",
    "X_test_pca = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5851063829787234\n",
      "[[41  3 21  6  4]\n",
      " [ 3 32 21  2 10]\n",
      " [10  8 55  9 17]\n",
      " [ 3  1  3 45 10]\n",
      " [ 4  3  7 11 47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       heart       0.67      0.55      0.60        75\n",
      "        long       0.68      0.47      0.56        68\n",
      "        oval       0.51      0.56      0.53        99\n",
      "       round       0.62      0.73      0.67        62\n",
      "      square       0.53      0.65      0.59        72\n",
      "\n",
      "    accuracy                           0.59       376\n",
      "   macro avg       0.60      0.59      0.59       376\n",
      "weighted avg       0.60      0.59      0.58       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train a random forest classifier and print the accuracy and confusion matrix\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "rf.fit(X_train_pca, Y_train)\n",
    "Y_pred = rf.predict(X_test_pca)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(classification_report(Y_test,Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.601063829787234\n",
      "[[47  8 12  4  4]\n",
      " [ 7 44 11  1  5]\n",
      " [15 11 56  8  9]\n",
      " [ 5  2  3 46  6]\n",
      " [ 7 15  7 10 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       heart       0.58      0.63      0.60        75\n",
      "        long       0.55      0.65      0.59        68\n",
      "        oval       0.63      0.57      0.60        99\n",
      "       round       0.67      0.74      0.70        62\n",
      "      square       0.58      0.46      0.51        72\n",
      "\n",
      "    accuracy                           0.60       376\n",
      "   macro avg       0.60      0.61      0.60       376\n",
      "weighted avg       0.60      0.60      0.60       376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aksde\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# train a KNN classifier and print the accuracy and confusion matrix\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_pca, Y_train)\n",
    "Y_pred = knn.predict(X_test_pca)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6117021276595744\n",
      "[[48  3 17  2  5]\n",
      " [ 7 31 19  0 11]\n",
      " [14  7 67  3  8]\n",
      " [ 4  3  7 41  7]\n",
      " [ 7  8  8  6 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       heart       0.60      0.64      0.62        75\n",
      "        long       0.60      0.46      0.52        68\n",
      "        oval       0.57      0.68      0.62        99\n",
      "       round       0.79      0.66      0.72        62\n",
      "      square       0.58      0.60      0.59        72\n",
      "\n",
      "    accuracy                           0.61       376\n",
      "   macro avg       0.63      0.61      0.61       376\n",
      "weighted avg       0.62      0.61      0.61       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train a LDA classifier and print the accuracy and confusion matrix\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train_pca, Y_train)\n",
    "Y_pred = lda.predict(X_test_pca)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(classification_report(Y_test,Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6090425531914894\n",
      "[[40  3 20  9  3]\n",
      " [ 8 42  7  1 10]\n",
      " [15  8 66  3  7]\n",
      " [ 4  3  6 41  8]\n",
      " [ 1 11 12  8 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       heart       0.59      0.53      0.56        75\n",
      "        long       0.63      0.62      0.62        68\n",
      "        oval       0.59      0.67      0.63        99\n",
      "       round       0.66      0.66      0.66        62\n",
      "      square       0.59      0.56      0.57        72\n",
      "\n",
      "    accuracy                           0.61       376\n",
      "   macro avg       0.61      0.61      0.61       376\n",
      "weighted avg       0.61      0.61      0.61       376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aksde\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train a MLP classifier and print the accuracy and confusion matrix\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500)\n",
    "mlp.fit(X_train_pca, Y_train)\n",
    "Y_pred = mlp.predict(X_test_pca)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.601063829787234\n",
      "[[43  4 17  4  7]\n",
      " [ 8 34 12  0 14]\n",
      " [16  7 61  8  7]\n",
      " [ 5  3  4 42  8]\n",
      " [ 4 10  7  5 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       heart       0.57      0.57      0.57        75\n",
      "        long       0.59      0.50      0.54        68\n",
      "        oval       0.60      0.62      0.61        99\n",
      "       round       0.71      0.68      0.69        62\n",
      "      square       0.56      0.64      0.60        72\n",
      "\n",
      "    accuracy                           0.60       376\n",
      "   macro avg       0.61      0.60      0.60       376\n",
      "weighted avg       0.60      0.60      0.60       376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aksde\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# train a logistic regression classifier and print the accuracy and confusion matrix\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "logreg.fit(X_train_pca, Y_train)\n",
    "Y_pred = logreg.predict(X_test_pca)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(classification_report(Y_test,Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5292553191489362\n",
      "[[38  3 20  8  6]\n",
      " [ 8 31 18  2  9]\n",
      " [15  9 50  7 18]\n",
      " [ 4  2  7 40  9]\n",
      " [ 5  8  5 14 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       heart       0.54      0.51      0.52        75\n",
      "        long       0.58      0.46      0.51        68\n",
      "        oval       0.50      0.51      0.50        99\n",
      "       round       0.56      0.65      0.60        62\n",
      "      square       0.49      0.56      0.52        72\n",
      "\n",
      "    accuracy                           0.53       376\n",
      "   macro avg       0.54      0.53      0.53       376\n",
      "weighted avg       0.53      0.53      0.53       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train a gradient boosting classifier and print the accuracy and confusion matrix\n",
    "gb = ensemble.GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0)\n",
    "gb.fit(X_train_pca, Y_train)\n",
    "Y_pred = gb.predict(X_test_pca)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(classification_report(Y_test,Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5930851063829787\n",
      "[[41  6 15  7  6]\n",
      " [10 36 13  0  9]\n",
      " [16  7 65  6  5]\n",
      " [ 6  3  8 40  5]\n",
      " [ 5 10  9  7 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       heart       0.53      0.55      0.54        75\n",
      "        long       0.58      0.53      0.55        68\n",
      "        oval       0.59      0.66      0.62        99\n",
      "       round       0.67      0.65      0.66        62\n",
      "      square       0.62      0.57      0.59        72\n",
      "\n",
      "    accuracy                           0.59       376\n",
      "   macro avg       0.60      0.59      0.59       376\n",
      "weighted avg       0.59      0.59      0.59       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train a SVM classifier and print the accuracy and confusion matrix\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train_pca, Y_train)\n",
    "Y_pred = svm.predict(X_test_pca)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(classification_report(Y_test,Y_pred))\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64fa2b2825e64e578aa23e103313040834779d60b029c1989c607f6f0d214853"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
